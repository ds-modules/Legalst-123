{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [LEGALST-123] Lab 05: Central Limit Theorem, Confidence Intervals, Hypothesis Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datascience import *\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "In this lab, we aim to prepare students for prediction exercises in PSET 1 and PSET 2 by allowing students to contextualize the statistical ideas of the Central Limit Theorem and hypothesis testing by using a dataset containing continuous variables. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "<hr style=\"border: 1px solid #fdb515;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data & Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this lab, we'll be using the same datasets used in our previous labs: the Nashville police stops dataset. Run the following cell below to read the `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops = pd.read_csv(\"https://github.com/ds-modules/data/raw/main/LS123_nashville_sample.csv\", index_col=0)\n",
    "stops.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's refer back to our last lab, where we explored different distributions using histograms. In particular, we looked at the distribution of stop counts for `\"subject_sex\"` and `\"subject_age\"`. For this notebook, let's look at the distribution of **age for each race**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "<div class=“alert alert-warning”>\n",
    "\n",
    "#### **Question 1.1**:\n",
    "Before explore these variables, let's clean the dataset. In the code cell below, drop any columns that have \"raw\" in their column names. Then, drop the rows with *any* null values EXCEPT for the columns` \"contraband_found\"`, `\"contraband_drugs\"`, `\"contraband_weapons\"`, `\"search_basis\"`, and `\"notes\"`.\n",
    "</div>\n",
    "\n",
    "Hint: Look at Lab 04 question 1.1 and question 1.2! It should be very similar. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR ANSWER HERE. You can use more or less lines than provided below. \n",
    "... \n",
    "... \n",
    "...\n",
    "stops = ...\n",
    "\n",
    "stops.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explore the columns `\"subject_race\"` and `\"subject_age\"`. For convenience, we have provided code below showing what race/ethincity categories exist within the column  `\"subject_race\"`. For this particular question, let's look at the distribution of people who are categorized as `'hispanic'` or `'white'` for `\"subject_race\"`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops[\"subject_race\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "<div class=“alert alert-warning”>\n",
    "\n",
    "#### **Question 1.2**:\n",
    "\n",
    "In the cell below, use Plotly to plot a histogram showing the distribution of age for people who are categorized as Hispanic with the y axis representing percentage. To do this, first create a table called `subject_hispanic` with your manipulations. Use `range_x=[0,80]` to properly scale the histogram.\n",
    "\n",
    "Hint 1: [here](https://plotly.github.io/plotly.py-docs/generated/plotly.express.histogram.html) is the documentation for Plotly's histogram method.\n",
    "\n",
    "Hint 2: Take a look at the `histnorm` attribute of the histogram method!\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "subject_hispanic = ... \n",
    "\n",
    "px.histogram(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Find the 25th, 50th, 75th percentile of `subject_hispanic` below.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# Find the 25th percentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the 50th percentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the 75th percentile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "<div class=“alert alert-warning”>\n",
    "\n",
    "#### **Question 1.3**:\n",
    "\n",
    "Now, follow the same process for people who are categorized as White. Again, to do this, first create a table called `subject_white` with your manipulations.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "subject_white = ... \n",
    "\n",
    "px.histogram(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Find the 25th, 50th, 75th percentile of `subject_white` below.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# Find the 25th percentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the 50th percentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the 75th percentile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "<div class=“alert alert-warning”>\n",
    "\n",
    "#### **Question 1.4**:\n",
    "\n",
    "Now, create an overlaid historgram comparing the two distributions.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR ANSWER HERE\n",
    "combined = pd.concat(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What do you notice about the two distributions? How do they compare?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_YOUR ANSWER HERE_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bootstrapping and the Confidence Interval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bootstrapping is a statistical technique that allows us to make educated guesses about a population using only a small sample from that population. It works by repeatedly taking small random samples from the data we have and then using these samples to estimate things like averages, variances, or other statistics, as if we had data for the entire population. This technique helps us understand how uncertain or variable our estimates are and is especially useful when we don't have access to the whole population's data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  A Random Sample and an Estimate\n",
    "Let's first draw from the sample, at random with replacement, the same number of times as the original sample size.\n",
    "\n",
    "It is important to resample the same number of times as the original sample size. The reason is that the variability of an estimate depends on the size of the sample.\n",
    "\n",
    "If we drew  at random without replacement, we would just get the same sample back. By drawing with replacement, we create the possibility for the new samples to be different from the original, because some participants might be drawn more than once and others not at all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell a few times to see how the distribution varies\n",
    "h_resampled = stops[stops['subject_race'] == 'hispanic'].sample(len(stops['subject_race'] == 'hispanic'), replace = True)\n",
    "\n",
    "title = 'Bootstrapped Distribution of Age among the Hispanic Population in our Dataset'\n",
    "px.histogram(h_resampled, x='subject_age', histnorm='percent', range_x=[0, 80], title=title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resampling from the Sample\n",
    "\n",
    "By resampling again and again, we can get many such estimates, and hence an `empirical distribution` of the estimates.\n",
    "\n",
    "Let us collect this code and define a function one_bootstrap_mean that returns one bootstrapped mean of `subject_age`, based on bootstrapping our original dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_bootstrap_mean():\n",
    "    resampled =  stops[stops['subject_race'] == 'hispanic'].sample(len(stops['subject_race'] == 'hispanic'), replace = True)\n",
    "    bootstrapped_mean = np.mean(resampled['subject_age'])\n",
    "    return bootstrapped_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell below a few times to see how the bootstrapped means vary. Remember that each of them is an estimate of the population mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_bootstrap_mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now repeat the bootstrap process multiple times by running a `for` loop as usual. In each iteration, we will call the function `one_bootstrap_mean` to generate one value of the bootstrapped mean based on our original dataset. Then we will append the boostrapped mean to the collection array `bstrap_means`.\n",
    "\n",
    "Let's do 2000 repetitions for this round of bootstrapping! (since this is a large number the code might take a while to run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_repetitions = 10000\n",
    "bstrap_means = make_array()\n",
    "for i in np.arange(num_repetitions):\n",
    "    bstrap_means = np.append(bstrap_means, one_bootstrap_mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's visualize what we got from the bootstrapped process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Distribution of Bootstrapped Mean Age Amongst Hispanic Population'\n",
    "px.histogram(bstrap_means,histnorm='percent', title=title)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confidence Intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confidence intervals are an important tool in data science. They help us create an estimate of a population parameter from a subset of the data. Here, we are using a 95% confidence interval to guess the average age of the Hispanic population that has been stopped by police."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the endpoints of the 95% confidence interval\n",
    "left = percentile(2.5, bstrap_means)\n",
    "right = percentile(97.5, bstrap_means)\n",
    "\n",
    "make_array(left, right)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's add the confidence interval to the histogram above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Distribution of Bootstrapped Mean Age Amongst Hispanic Population'\n",
    "fig = px.histogram(bstrap_means,histnorm='percent', title=title)\n",
    "fig.add_shape(type='line', x0=left, y0=0, x1=right, y1=0, line_color='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, you can visualize our estimate for the population age as displayed by the red line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Central Limit Theorem (CLT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The Central Limit Theorem (CLT)** is a fundamental concept in statistics that has significant implications for making inferences about populations based on samples. It states that, regardless of the shape of the original population distribution, the distribution of the sample means will approach a normal distribution as the sample size increases. This is true as long as the sample size is sufficiently large."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The significance of the Central Limit Theorem lies in its ability to provide a bridge between the characteristics of a population and the properties of the sample means drawn from that population.\n",
    "\n",
    "**Population Mean:**\n",
    "\n",
    "The Central Limit Theorem tells us that the sampling distribution of the mean of a random sample will be approximately normally distributed, even if the population distribution is not normal.\n",
    "This is crucial because it allows us to make inferences about the population mean using statistical methods that assume a normal distribution.\n",
    "\n",
    "**Sample Size:**\n",
    "\n",
    "The larger the sample size, the closer the distribution of the sample mean will be to a normal distribution according to the CLT.\n",
    "As the sample size increases, the standard deviation of the sampling distribution decreases. This means that larger sample sizes provide more precise estimates of the population mean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To demonstrate this, let's look at the original dataset and data we obtained from bootstrapping above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Bootstrapped Distribution of Age among the Hispanic Population in our Dataset'\n",
    "px.histogram(h_resampled, x='subject_age', histnorm='percent', range_x=[0, 80], title=title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's look at the distribution of bootstrapped mean amongst this sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Distribution of Bootstrapped Mean Age Amongst Hispanic Population'\n",
    "px.histogram(bstrap_means,histnorm='percent', title=title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from above, the original distribution looks nothing like a normal distribution, but the bootstrapped means still follow a somewhat normal shape."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's connect the Central Limit Theorem to the motivation behind using **regression**:\n",
    "\n",
    "In regression analysis, the Central Limit Theorem is often invoked when dealing with the distribution of the regression coefficients.\n",
    "The ordinary least squares (OLS) estimators, which are commonly used in regression analysis, are unbiased and efficient under the assumption of normally distributed errors.\n",
    "The CLT justifies the use of statistical tests and confidence intervals for regression coefficients, as it ensures that the distribution of these coefficients becomes approximately normal as the sample size increases.\n",
    "\n",
    "In summary, the Central Limit Theorem is significant because it allows statisticians to make valid inferences about population parameters, particularly the population mean, based on samples. This is crucial in various fields, including regression analysis, where assumptions about the distribution of coefficients play a key role in drawing conclusions about relationships between variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using bootstrapping to arrive at a distribution of a test statistic\n",
    "\n",
    "Here, we are testing whether the underlying distribution of age is the same amongst Hispanic and White populations in the Nashville traffic stops using a 5% p-value cutoff. The test statistic being used is the difference between the average ages. The null hypothesis here would be that the average age of Hispanic drivers stopped is *not* less than the average age of white drivers stopped. So really the question we are getting at is whether or not we can reject the null hypothesis (H<sub>0</sub>).\n",
    "\n",
    "This sort of classical hypothesis test for trying to determine whether samples come from different underlying populations is commonly accomplished by using the t-statistic. When we talk about regression coefficients next time, we will see that the analysis typically includes a classical hypothesis test for whether we can reject the null hypothesis (i.e., that the coefficient may be zero and so the variable has no effect on the outcome). Here we are simulating a one-sided Student's t-test for independently sampled means by creating an underlying population mean distribution using bootstrapping and then asking how likely our test statistic is under the assumption that the null hypothesis is true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe of subject age and subject race\n",
    "# define a test statistic--difference in sample means\n",
    "# use boostrapping to create samples (of the same size as the original data) and calculate the mean for each sample\n",
    "# record the means, calculate the test statistic for each sampling run\n",
    "\n",
    "ab_dataframe = combined[['subject_age', 'subject_race']]\n",
    "test_stat = np.mean(ab_dataframe[ab_dataframe['subject_race'] == 'hispanic']['subject_age']) - np.mean(ab_dataframe[ab_dataframe['subject_race'] == 'white']['subject_age'])\n",
    "\n",
    "simulated_stats = []\n",
    "\n",
    "for i in range(10000):\n",
    "    new_column = ab_dataframe.sample(ab_dataframe.shape[0], replace=True).reset_index()['subject_race']\n",
    "\n",
    "    sampled = ab_dataframe.copy()\n",
    "    sampled.loc[:, 'shuffled'] = new_column\n",
    "\n",
    "    new_stat = np.mean(sampled[sampled['shuffled'] == 'hispanic']['subject_age']) - np.mean(sampled[sampled['shuffled'] == 'white']['subject_age'])\n",
    "    simulated_stats = np.append(simulated_stats, new_stat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Our observed test statistic is', test_stat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the 95% confidence interval bounds, remembering that it is one-sided hypothesis\n",
    "# note that we needed to make sure there are no NaNs to use the 'np.quantile' function\n",
    "lower = ...\n",
    "upper = ...\n",
    "print(\"lower bound of 95% confidence interval: \", lower,\" upper bound of 95% confidence interval: \", upper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Boostrapped Distribution of Difference in Mean Age Between Hispanic and White Drivers Stopped'\n",
    "fig = px.histogram(simulated_stats, histnorm='percent', title=title)\n",
    "fig.add_shape(type='line', x0=lower, y0=0, x1=upper, y1=0, line_color='yellow', line_width=10)\n",
    "fig.add_shape(type='line', x0=test_stat, y0=0, x1=test_stat, y1=4, line_color='red', line_width=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the value of p, which the proportion of simulated means that are less than (remember this is a\n",
    "# one-sided test) the value of our test statistic for the sample\n",
    "# hint: use a list comprehension like we did just above\n",
    "\n",
    "p_val = ...\n",
    "print('our p value is', p_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this value is outside than our 0.05 cutoff *on the left tail of the distribution* (remember, we are doing a one-sided test), we are able to reject the null hypothesis that the mean age of Hispanic drivers stopped is not less than the mean age of white drivers stopped. In effect we are saying that it is very likely, given the test statistic from the sample, that Hispanic drivers are younger than white drivers in the population of people the Nashville police made traffic stops for.\n",
    "\n",
    "**Question:** What result would we have if we did a two-sided test, that is, if the null hypothesis was simply that the difference in mean ages between white and Hispanic drivers was zero? That is often the question we ask about regression coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
