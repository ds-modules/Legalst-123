{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OyK_ohUkPraG"
   },
   "source": [
    "# [LEGALST-123] Lab 17: Parsing XML Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KwWTi_M5PraK"
   },
   "source": [
    "This lab will cover parsing XML and attribute lookup, Beautiful Soup, and web scraping.\n",
    "\n",
    "*Estimated Time: 45 Minutes *\n",
    "\n",
    "### Topics Covered:\n",
    "- XML syntax\n",
    "- locating content with Beautiful Soup\n",
    "- Web scraping\n",
    "\n",
    "### Table of Contents\n",
    "\n",
    "[The Data](#section-data)<br>\n",
    "1 - [Web Scraping](#section-1)<br>\n",
    "2 - [XML Syntax](#section-2)<br>\n",
    "3 - [Using Beautiful Soup to parse XML](#section-3)<br>\n",
    "4 - [Putting it all in a dataframe](#section-4)<br>\n",
    "\n",
    "**Dependencies:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xml.etree.cElementTree as ET #XML Parser\n",
    "from lxml import etree #ElementTree and lxml allow us to parse the XML file.\n",
    "import requests #make request to server\n",
    "import time #pause loop\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6SUNENg-PraU"
   },
   "source": [
    "----\n",
    "## The Data<a id='section-data'></a>\n",
    "\n",
    "In this notebook, you'll be working with XML files from the Old Bailey API (https://www.oldbaileyonline.org/obapi/). These files contain the proceedings of all trials from 1674 to 1913. For this lab, we'll go through the trials from 1754-1756 and 1824-1826. XML (eXtensible Markup Language) provides a hierarchical representation of data contained within different tags and nodes. We'll go over XML syntax later. We will learn how to parse through these XML files from Old Bailey and grab information from sections of an XML file.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FRiFQ0xNPrbh"
   },
   "source": [
    "----\n",
    "## Section 1: Web Scraping<a id='section-1'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "maI4gqRPPrbi"
   },
   "source": [
    "First we will go through how to parse one XML file. The Old Bailey API has a total of **197751** cases. Fortunately, we are only going to use the ones from 1754-1756 and 1824-1826, but that still only narrows the number of cases to 6506! \n",
    "\n",
    "Don't worry though, you're not going to manually download each case yourself. This is where web scraping comes into play. With web scraping, we can automate data collection to get all 6506 cases. \n",
    "\n",
    "Before we start scraping, we need to know how `requests` works. The `requests` library gets (`.get`!) you a response object from a web server and will automatically decode the content from the server, from which you can use `.text` to see the document! Requests through the Old Bailey API will return an XML file, which we can then write as a file and save.\n",
    "\n",
    "Let's take a look at all of the terms we can use to choose the specific cases we want. We use `.json()` here since the parameters are stored as a JSON object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 181
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 569,
     "status": "error",
     "timestamp": 1584242564840,
     "user": {
      "displayName": "Violet Yao",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiFt1BCGd8JlHSVKhi8kVxouO0J-pkDwzodp18k6w=s64",
      "userId": "10253555746784075040"
     },
     "user_tz": 420
    },
    "id": "FzJc-Z-dPrbi",
    "outputId": "5103194b-863c-4c0a-b752-4a58c4ef2d4b",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rjson = requests.get('http://www.oldbaileyonline.org/obapi/terms').json()\n",
    "rjson "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EM9zTvLNPrbk"
   },
   "source": [
    "If you wanted to explore the full list in your web browser, click [this link](https://www.oldbaileyonline.org/obapi/terms). \n",
    "\n",
    "Now that you've had a chance to look through some of the terms, let's see how to grab the specific XML files.\n",
    "\n",
    "Clicking the URL below returns a JSON object of the number of IDs and the frequency of each term in which every trial contains the term \"sheffield\" and the offence categrory \"deception\" from June 14th, 1847 onward. Also, each trial ID that satisfies the terms is returned; the count parameter in this case returns 10 trial IDs, but if left unspecified, the API will return a maximum count of 1000 IDs. \n",
    "\n",
    "https://www.oldbaileyonline.org/obapi/ob?term0=trialtext_sheffield&term1=offcat_deception&term2=fromdate_18470614&breakdown=offsubcat&count=10&start=0\n",
    "\n",
    "Although the terms for time are listed as numbers, the format for the term is\n",
    "`fromdate_(starting date)` and `todate_(ending date)` without the parentheses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Zp7TXx3WPrbl"
   },
   "source": [
    "**Question 1.1:** Use requests.get(...) to get the all trial IDs between the years 1754 and 1756 and return it as a JSON object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b9kOCZ2HPrbn",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "trials = ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9paTSQLwPrbo"
   },
   "source": [
    "Now, lets pick some trials from `trial['hits']`, so we have a list of IDs we can work with. \n",
    "\n",
    "**Question 1.2:** Select the first 10 trials by splicing through the list that we retrieved from the previous cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5Tkvn-R7Prbq"
   },
   "outputs": [],
   "source": [
    "first_10 = ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "puWGLo37Prbs"
   },
   "source": [
    "Using the trial IDs from the previous cell, we are going to format the URL in a way so that we can get the XML file for each trial. In order to get the XML file using the Old Bailey API, we must follow this URL format:\n",
    "\n",
    "<p style=\"text-align: center;\">`http://www.oldbaileyonline.org/obapi/text?div=(enter trial ID here without parenthesis)`  </p>\n",
    "\n",
    "For example, http://www.oldbaileyonline.org/obapi/text?div=t16740429-1 gives you the link to the XML file of the first proceeding in the database.\n",
    "\n",
    "\n",
    "**Question  1.3:** Get the XML file of the first trial in first_10. A successful `.get` request returns `<Response [200]>`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 429,
     "status": "ok",
     "timestamp": 1581022295239,
     "user": {
      "displayName": "Violet Yao",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB71gFX2MIVV9B2u98jEr6NxRAe3zZexUayLswnlg=s64",
      "userId": "10253555746784075040"
     },
     "user_tz": 480
    },
    "id": "UTuUSmdLPrbu",
    "outputId": "3dfe9e3b-a68a-49a7-a0a9-7c33a2e6f50c",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "...\n",
    "response = ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WffFWa9rPrbv"
   },
   "source": [
    "Run the next cell to see the XML format of the text! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 887
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 529,
     "status": "ok",
     "timestamp": 1581022301672,
     "user": {
      "displayName": "Violet Yao",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB71gFX2MIVV9B2u98jEr6NxRAe3zZexUayLswnlg=s64",
      "userId": "10253555746784075040"
     },
     "user_tz": 480
    },
    "id": "UaGyPfyjPrbw",
    "outputId": "e38f0bb3-5ab5-403d-a229-01bd5a6ed654",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pADUsBtjPrbx"
   },
   "source": [
    "We can save the XML file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 198
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 647,
     "status": "error",
     "timestamp": 1581022307915,
     "user": {
      "displayName": "Violet Yao",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB71gFX2MIVV9B2u98jEr6NxRAe3zZexUayLswnlg=s64",
      "userId": "10253555746784075040"
     },
     "user_tz": 480
    },
    "id": "BPjM1haCPrbx",
    "outputId": "3d582eed-942a-4956-fd50-a5806460f3fe"
   },
   "outputs": [],
   "source": [
    "with open(f'data/old-bailey/old-bailey-{first_trial_id}.xml', 'w') as file:\n",
    "    file.write(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll get trial `t17031013-13` specifically, for the examples below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "davis_trial_id = 't17031013-13'\n",
    "response = requests.get(f'http://www.oldbaileyonline.org/obapi/text?div={davis_trial_id}')\n",
    "with open(f'data/old-bailey/old-bailey-{davis_trial_id}.xml', 'w') as file:\n",
    "    file.write(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KR7GETNQPrby"
   },
   "source": [
    "### Challenge: Scraping all trials from 1754 - 1756\n",
    "\n",
    "Now that you know how to find the trial IDs for certain parameters as well as get an XML file using `requests.get(some_url)`, iterate through each ID in the list of trials (use `trials['hits']` for the list of IDs) we got from 1754-1756 earlier. You can choose how many trials you want to save."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_LtgnpPpPrbz"
   },
   "outputs": [],
   "source": [
    "for trial in ...:\n",
    "    # format URL\n",
    "    \n",
    "    # get text from URL\n",
    "    \n",
    "    # store in data/old-bailey/file_name\n",
    "    \n",
    "    # one second pause so servers aren't overloaded\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iAvriff2Prb2"
   },
   "source": [
    "You can check if you saved the XML files by executing the cell below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2j2KSL8mPrb2"
   },
   "outputs": [],
   "source": [
    "!ls data/old-bailey/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JtKSmptxPrb4"
   },
   "source": [
    "This cell will show you the XML file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b-JSzqUBPrb5"
   },
   "outputs": [],
   "source": [
    "!cat data/old-bailey/old-bailey-t17540116-1.xml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-TH1jtitPraW"
   },
   "source": [
    "## Section 2: XML Syntax<a id='section-2'></a>\n",
    "\n",
    "First, we'll go over the syntax of a XML file. The basic unit of XML code is called an \"element\" or \"node\" and has a start and ending tag. The tags for each element look something like this:\n",
    "\n",
    "<p style=\"text-align: center;\"> `<exampletag>some text</exampletag>`  </p>\n",
    "\n",
    "Run the next cell to look at the XML file of one of the cases from the OldBailey API!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9K9VKN8fPraY",
    "outputId": "84e2e1b5-62be-4569-8a58-689e02c0dda5"
   },
   "outputs": [],
   "source": [
    "# use requests to get an example of xml\n",
    "example = requests.get(f'https://www.oldbaileyonline.org/obapi/text?div={davis_trial_id}')\n",
    "print(example.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BOIUR1SSPraf"
   },
   "source": [
    "The `interp` tags at the beginning of the file are elements that don't have any plain text content. Note that elements may possibly be empty and not contain any text (i.e. `interp` elements mentioned earlier). If the element is empty, the tag may follow a format that looks similar to `<exampletag/>`, which is equivalent to `<exampletag></exampletag>`.\n",
    "\n",
    "Elements may also contain other elements, which we call \"children\". Most children are indented, but the indents aren't necessary in XML and are used for clarity to show nesting. For example, if we go down to `<persName id=\"t17540116-4-defend46\" type=\"defendantName\">` , we see that the `rs` tag is a child of `persName`. We will explore about children in XML more in the next section. \n",
    "\n",
    "Lastly, elements may have attributes, which are in the format `<exampletag name_of_attribute=\"somevalue\">`. Attributes are designed to store data related to a specific elements. Attributes **must** follow the quotes format (`name = \"value\"`). As you can tell, in this XML file, attributes are everywhere!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AkseGV_hPrah"
   },
   "source": [
    "-----\n",
    "**Question 2.1:** What was the verdict of this case? Was there a punsihment and if so, what was it? List both and state whether you found it as plain text content or as an attribute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_9tJ_ejwPrai"
   },
   "source": [
    "Write your answer here:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DZs0PgQmPrap"
   },
   "source": [
    "----\n",
    "## Section 3: Using Beautiful Soup to parse XML<a id='section-3'></a>\n",
    "\n",
    "Now that we know what the syntax and structure of an XML file, let's figure out how to parse through one! We are going to load the same file from the second section and use Beautiful Soup to navigate through elements in this file. \n",
    "\n",
    "First, we need to import the file into a Beautiful Soup instance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KZIKoc7dPraq"
   },
   "outputs": [],
   "source": [
    "xml_file = f'data/old-bailey/old-bailey-{davis_trial_id}.xml'\n",
    "xml_file = open(xml_file).read()\n",
    "davis_trial_soup = BeautifulSoup(xml_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can examine `davis_trial_soup` using `.contents`, which puts all children of a tag in a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "davis_trial_soup.contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice that all information we care about is contained within `<div>` and `</div1>` tags, so we navigate to it. The simplest way to navigate the parse tree is to say the name of the tag you want (`.`). In this case, we want to access div1 under body tag, which is under html tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "body = davis_trial_soup.html.body.div1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now start working down the tree! With the body, we can find each child of the body by printing the tags. This will also help us for future reference, if we every want to go through other children in the XML file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for child in body.children:\n",
    "    if child.name:\n",
    "        print(child.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a list of children to work with let's select one using `.`. Using `.` navigates through the hierarchical structure of XML and helps us keep track of the path we are taking through this file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "choose_p = body.p\n",
    "for child in choose_p.children:\n",
    "    if child.name:\n",
    "        print(child.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This isn't very helpful, since we're still left with a bunch of tags and on top of that, we have a lot of repeating tags and names. Let's choose `placename` as our next tag and see what happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "place_name = body.p.placename\n",
    "for child in place_name.children:\n",
    "    if child.name:\n",
    "        print(child.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nothing was printed, so it looks like we hit the end! Let's use `.string` to examine the data in this element, following the `.` path we used to get here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(body.p.placename.string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.1:** Find the defendant's name by traversing through the correct elements. You can check your answer with printed XML using `soup.contents`\n",
    "\n",
    "You may find `body.p.persname.string` returns None. It is becasue if a tag, `body.p.persname.string` in this case, contains more than one thing, then it’s not clear what .string should refer to, so .string is defined to be None. Which functions could help us locate the name instead?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B08ehQmMPrbN",
    "outputId": "f0158484-bf40-4dc1-d357-05b3c9772f2d",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e0KUeGviPrbg"
   },
   "source": [
    "**Question 2.2:** Since the textual data is pretty messy in the XML files of these proceedings, where do you think the data you need might be held and how might you go about extracting this data? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZR3n0Gu6Prbh"
   },
   "source": [
    "*Write your response here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "60oOKGf9Prb6"
   },
   "source": [
    "----\n",
    "## Section 4: Putting it all in a dataframe<a id='section-4'></a>\n",
    "\n",
    "Now that we have a bunch of XML files and know how to parse through them to extract data, let's put the data from the XML files into a dataframe. Take a look at the XML for [this trial](https://www.oldbaileyonline.org/obapi/text?div=t17031013-13) (and even better, look at what is or isn't consistent between that one and some others), and think about the structure of the data. How would you identify the people involved in a case? How would you identify their roles (witness/defendant/victim/other), or their genders? What can you learn about the alleged offence?\n",
    "\n",
    "*Note:* Some cases have multiple defendants, multiple victims or multiple witnesses; however, most cases only have at most one of each. You can represent this in a dataframe by having $N$ columns for each property of a defendant, victim, etc., but this results in many many empty cells, and may not be amenable to analysis for the questions you come up with.\n",
    "\n",
    "Think about the kinds of questions you may want to ask about this data, and refer to the XML for how you might answer them. For example, you may be interested in\n",
    "\n",
    "- the words used specifically in describing the crime (notice that the text specifically between `<rs id=\"...\" type=\"offenceDescription\">` and `</rs>` gives you this)\n",
    "\n",
    "- whether any victim was female\n",
    "\n",
    "- whether any defendant was female\n",
    "\n",
    "- the `category` (or `subCategory`) of the offense, etc.\n",
    "\n",
    "- the entire text of the trial (sans tags)\n",
    "\n",
    "These are questions that can be answered for most if not all cases, so they make good candidates for names of columns.\n",
    "\n",
    "**Question 4.1**: Start by completing the following function to get the date of the case and return it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def case_date(case_soup):\n",
    "    ...\n",
    "\n",
    "print(\"Case\", davis_trial_id, \"happened on\", case_date(davis_trial_soup))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.2**: Complete the following function finding every person in a trial, and returning a list of dictionaries of their attributes (e.g. `[{\"surname\": \"FINCH\", \"given\": \"JOHN\", \"gender\": \"male\", \"type\": \"witnessName\"}]`). Test it on `davis_trial_soup` used before. **Note:** If you use `find_all`, specify the tag name in lowercase, as beautifulsoup lowercases all tag names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def people_in_case(case_soup):\n",
    "    ...\n",
    "\n",
    "... # test on davis_soup_trial and others"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.3**: Complete the following function to find the `offenseDescription` and `verdictDescription` in a trial. Think about how [the XML](https://www.oldbaileyonline.org/obapi/text?div=t17031013-13) expresses the offenseDescription and verdictDescription, and see if you can write the code without specifically looking for the labels \"offenseDescription\" and \"verdictDescription\" (i.e. so that it will work even if a case came up with something like `<rs type=\"sentencingDescription\">`). Get the category, subCategory and textual description of the offense:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def case_descriptions(case_soup):\n",
    "    ...\n",
    "\n",
    "... # test on davis_soup_trial and others\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.4:** Once you get this far, you've learned how to parse most of the data provided in the Old Bailey XML. Now, think about the data you now have access to for each case, and complete the following function creating a dataframe describing all of trials in `trials[\"hits\"][:100]`.\n",
    "\n",
    "One easy way to do this is to make a list of dictionaries, and pass this to `pd.DataFrame`, as in the following example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame([{\"x\": 1, \"y\": 10}, {\"y\": 12, \"z\": 111}])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the questions you may want to ask about the data, and complete the following function to put it all together in a DataFrame:\n",
    "\n",
    "*Note!:* This is not easy. Take it one step at a time, initially just making one a DataFrame with one column, and building up from there. I made several little errors while writing it up (take note of capitalization in property names like `offenceSubcategory` and to spell it 'offence' not 'offense' (i.e. the British way)). **The rewarding thing** is that once you've written this up, as you come up with new questions to ask about the case data you'll be able to easily add columns to use in your analysis.\n",
    "\n",
    "*If you are stuck*, try looking at the *data output* of the solutions (avoid looking at the code until you've worked through it), picking *one* column, and thinking of how you can answer that with the functions you've made or learned already."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import nan # you may find this useful, but it's not crucial\n",
    "def table_of_cases(xml_file_names):\n",
    "    rows = []\n",
    "    for xml_file in xml_file_names:\n",
    "        with open(f'data/old-bailey/old-bailey-{xml_file}.xml', \"r\") as xml_file:\n",
    "            case = BeautifulSoup(xml_file)\n",
    "        ...\n",
    "        row = ...\n",
    "        ...\n",
    "        rows.append(row)\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "table_of_cases([davis_trial_id]) # tests on just one case\n",
    "... # run table_of_cases on a list of the 30 cases we fetched above\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JIjKFhrJPrcC"
   },
   "source": [
    "Phew, that's it! Now you know how to parse through XML files using Beautiful Soup and web scrape using the `requests` library! This was a long lab, so pat yourself on the back for working through it. It will help you on problem set 3 enormously.\n",
    "\n",
    "If you leaned heavily on the given lab solutions, make sure you understand every line, and **ask questions when you don't**. You can test your understanding by adding extending the solutions with more columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VRwXZDiDPrcD"
   },
   "source": [
    "## Bibliography\n",
    "\n",
    " - All files from Old Bailey API - https://www.oldbaileyonline.org/obapi/\n",
    " - ElementTree information adapted from Driscoll, Mike. (2013, April). Python 101 – Intro to XML Parsing with ElementTree.\n",
    " https://www.blog.pythonlibrary.org/2013/04/30/python-101-intro-to-xml-parsing-with-elementtree/\n",
    "\n",
    " - Web Scraping code adapted from MEDST-250 Notebook developed by Tejas Priyadarshan.\n",
    " https://github.com/ds-modules/MEDST-250/tree/master/04%20-%20XML_Day_1\n",
    " \n",
    " - Image source from https://www.researchgate.net/publication/257631377_Efficient_XML_Path_Filtering_Using_GPUs\n",
    "\n",
    "----\n",
    "Notebook developed by: Jason Jiang, Iland Leigh, Violet Yao, and Wilson Berkow\n",
    "\n",
    "Data Science Modules: http://data.berkeley.edu/education/modules"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "KR7GETNQPrby",
    "60oOKGf9Prb6",
    "VRwXZDiDPrcD"
   ],
   "name": "BS WIP Parsing_XML_Data_solutions.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "name": "python392jvsc74a57bd0aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "language_info": {
   "name": "python",
   "version": ""
  },
  "metadata": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}